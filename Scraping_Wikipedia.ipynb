{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will scrape one of the Wikipedia pages from the web. \n",
    "I will be using BeautifulSoup, requests libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Started with requests library\n",
    "Python library requests retrieves information from the web. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing requests library\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Pennsylvania'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code # success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Pennsylvania - Wikipedia</title>\n",
      "<script>document.documentElement.className=\"client-js\";RLCONF={\"wg\n"
     ]
    }
   ],
   "source": [
    "print(response.text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using requests with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">Pennsylvania</h1>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pennsylvania'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a disambiguation link for Pensillvania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a id=\"top\"></a>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wiki/Pennsylvania_(disambiguation)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(class_=\"mw-disambig\")['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'41°N 77.5°W'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(class_ = 'geo-dec').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prettify() methods gives a nice indented structure to an HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class=\"infobox geography vcard\" style=\"width:22em;width:23em\">\n",
      " <tbody>\n",
      "  <tr>\n",
      "   <th colspan=\"2\" style=\"text-align:center;font-size:125%;font-weight:bold;font-size:1.25em; white-space:nowrap\">\n",
      "    <div class=\"fn org\" style=\"display:inline\">\n",
      "     Pennsylvania\n",
      "    </div>\n",
      "   </th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <td colspan=\"2\" style=\"text-align:center;background-color:#cddeff; font-weight:bold;\">\n",
      "    <div class=\"category\">\n",
      "     <a href=\"/wiki/U.S._state\" title=\"U.S. state\">\n",
      "      State\n",
      "     </a>\n",
      "    </div>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <td colspan=\"2\" style=\"text-align:center;font-weight:bold;\">\n",
      "    Commonwealth of Pennsylvania\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <td class=\"maptable\" colspan=\"2\" style=\"text-align:center\">\n",
      "    <div style=\"display:table; width:100%; background:none;\">\n",
      "     <div style=\"display:table-row\">\n",
      "      <div style=\"display:table-cell;vertical-align:middle; text-align:center;\">\n",
      "       <a class=\"image\" href=\"/wiki/File:Flag_of_Pennsylvania.svg\" title=\"Flag of Pennsylvania\">\n",
      "        <img alt=\"Flag of Pennsylvania\" class=\"thumbborder\" data-file-height=\"450\" data-file-width=\"675\" decoding=\"async\" height=\"83\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Flag_of_Pennsylvania.svg/125px-Flag_of_Pennsylvania.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Flag_of_Pennsylvania.svg/188px-Flag_of_Pennsylvania.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Flag_of_Pennsylvania.svg/250px-Flag_of_Pennsylvania.svg.png 2x\" width=\"125\"/>\n",
      "       </a>\n",
      "       <div style=\"padding:0.2em 0 0.2em 0;\">\n",
      "        <a class=\"mw-redirect\" href=\"/wiki/Flag_of_Pennsylvania\" title=\"Flag of Pennsylvania\">\n",
      "         Flag\n",
      "        </a>\n",
      "       </div>\n",
      "      </div>\n",
      "      <div style=\"display:table-cell;vertical-align:middle; text-align:center;\">\n",
      "       <a class=\"image\" href=\"/wiki/File:Seal_of_Pennsylvania.svg\" title=\"Official seal of Pennsylvania\">\n",
      "        <img alt=\"Official seal of Pennsylvania\" data-file-height=\"289\" data-file-width=\"289\" decoding=\"async\" height=\"100\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Seal_of_Pennsylvania.svg/100px-Seal_of_Pennsylvania.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Seal_of_Pennsylvania.svg/150px-Seal_of_Pennsylvania.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Seal_of_Pennsylvania.svg/200px-Seal_of_Pennsylvania.svg.png 2x\" width=\"100\"/>\n",
      "       </a>\n",
      "       <div style=\"padding:0.2em 0 0.2em 0;\">\n",
      "        <a href=\"/wiki/Seal_of_Pennsylvania\" title=\"Seal of Pennsylvania\">\n",
      "         Seal\n",
      "        </a>\n",
      "       </div>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <td colspan=\"2\" style=\"text-align:center\">\n",
      "    <a class=\"mw-redirect\" href=\"/wiki/List_of_U.S._state_nicknames\" title=\"List of U.S. state nicknames\">\n",
      "     Nickname(s):\n",
      "    </a>\n",
      "    <div class=\"nickname\" style=\"display:inline\">\n",
      "     Keystone State;\n",
      "     <sup class=\"reference\" id=\"cite_ref-1\">\n",
      "      <a href=\"#cite_note-1\">\n",
      "       [1]\n",
      "      </a>\n",
      "     </sup>\n",
      "     Quaker State\n",
      "    </div>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <td colspan=\"2\" style=\"text-align:center\">\n",
      "    <a href=\"/wiki/List_of_U.S._state_and_territory_mottos\" title=\"List of U.S. state and territory mottos\">\n",
      "     Motto(s):\n",
      "    </a>\n",
      "    <div class=\"nickname\" style=\"display:inline\">\n",
      "     Virtue, Liberty and Independence\n",
      "    </div>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <td colspan=\"2\" style=\"text-align:center\">\n",
      "    <a href=\"/wiki/List_of_U.S._state_songs\" title=\"List of U.S. state songs\">\n",
      "     Anthem:\n",
      "    </a>\n",
      "    \"\n",
      "    <a href=\"/wiki/Pennsylvania_(song)\" title=\"Pennsylvania (song)\">\n",
      "     Pennsylvania\n",
      "    </a>\n",
      "    \"\n",
      "    <br/>\n",
      "    <div class=\"center\">\n",
      "     <div class=\"floatnone\">\n",
      "      <div class=\"mediaContainer\" style=\"width:220px\">\n",
      "       <audio class=\"kskin\" controls=\"\" data-durationhint=\"75.359614512472\" data-mwprovider=\"wikimediacommons\" data-mwtitle='\"Pennsylvania\"_-_Regional_anthem_of_Pennsylvania.ogg' data-startoffset=\"0\" id=\"mwe_player_0\" preload=\"none\" style=\"width:220px\">\n",
      "        <source data-bandwidth=\"210704\" data-height=\"0\" data-shorttitle=\"MP3\" data-title=\"MP3\" data-transcodekey=\"mp3\" data-width=\"0\" src=\"//upload.wikimedia.org/wikipedia/commons/transcoded/9/9c/%22Pennsylvania%22_-_Regional_anthem_of_Pennsylvania.ogg/%22Pennsylvania%22_-_Regional_anthem_of_Pennsylvania.ogg.mp3\" type=\"audio/mpeg\"/>\n",
      "        <source data-bandwidth=\"348997\" data-height=\"0\" data-shorttitle=\"Ogg source\" data-title=\"Original Ogg file (349 kbps)\" data-width=\"0\" src=\"//upload.wikimedia.org/wikipedia/commons/9/9c/%22Pennsylvania%22_-_Regional_anthem_of_Pennsylvania.ogg\" type='audio/ogg; codecs=\"vorbis\"'/>\n",
      "       </audio>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <td colspan=\"2\" style=\"text-align:center\">\n",
      "    <a class=\"image\" href=\"/wiki/File:Pennsylvania_in_United_States.svg\" title=\"Map of the United States with Pennsylvania highlighted\">\n",
      "     <img alt=\"Map of the United States with Pennsylvania highlighted\" data-file-height=\"731\" data-file-width=\"1181\" decoding=\"async\" height=\"186\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Pennsylvania_in_United_States.svg/300px-Pennsylvania_in_United_States.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Pennsylvania_in_United_States.svg/450px-Pennsylvania_in_United_States.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Pennsylvania_in_United_States.svg/600px-Pennsylvania_in_United_States.svg.png 2x\" width=\"300\"/>\n",
      "    </a>\n",
      "    <div style=\"padding:0.3em 0 0 0;\">\n",
      "     Map of the United States with Pennsylvania highlighted\n",
      "    </div>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th scope=\"row\">\n",
      "    Country\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/United_States\" title=\"United States\">\n",
      "     United States\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    Before statehood\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/Province_of_Pennsylvania\" title=\"Province of Pennsylvania\">\n",
      "     Province of Pennsylvania\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    <a href=\"/wiki/List_of_U.S._states_by_date_of_admission_to_the_Union#List_of_U.S._states\" title=\"List of U.S. states by date of admission to the Union\">\n",
      "     Admitted to the Union\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    December 12, 1787 (2nd)\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th scope=\"row\">\n",
      "    <a href=\"/wiki/List_of_capitals_in_the_United_States\" title=\"List of capitals in the United States\">\n",
      "     Capital\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/Harrisburg,_Pennsylvania\" title=\"Harrisburg, Pennsylvania\">\n",
      "     Harrisburg\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    <a class=\"mw-redirect\" href=\"/wiki/List_of_U.S._states%27_largest_cities_by_population\" title=\"List of U.S. states' largest cities by population\">\n",
      "     Largest city\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/Philadelphia\" title=\"Philadelphia\">\n",
      "     Philadelphia\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    <a class=\"mw-redirect\" href=\"/wiki/List_of_Metropolitan_Statistical_Areas\" title=\"List of Metropolitan Statistical Areas\">\n",
      "     Largest metro\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/Delaware_Valley\" title=\"Delaware Valley\">\n",
      "     Delaware Valley\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th colspan=\"2\" style=\"text-align:center;text-align:left\">\n",
      "    Government\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "    </div>\n",
      "   </th>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    •\n",
      "    <a class=\"mw-redirect\" href=\"/wiki/Governor_of_Pennsylvania\" title=\"Governor of Pennsylvania\">\n",
      "     Governor\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <span class=\"nowrap\">\n",
      "     <a href=\"/wiki/Tom_Wolf\" title=\"Tom Wolf\">\n",
      "      Tom Wolf\n",
      "     </a>\n",
      "     (\n",
      "     <a href=\"/wiki/Democratic_Party_(United_States)\" title=\"Democratic Party (United States)\">\n",
      "      D\n",
      "     </a>\n",
      "     )\n",
      "    </span>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    •\n",
      "    <a href=\"/wiki/Lieutenant_Governor_of_Pennsylvania\" title=\"Lieutenant Governor of Pennsylvania\">\n",
      "     Lieutenant Governor\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <span class=\"nowrap\">\n",
      "     <a href=\"/wiki/John_Fetterman_(politician)\" title=\"John Fetterman (politician)\">\n",
      "      John Fetterman\n",
      "     </a>\n",
      "     (D)\n",
      "    </span>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    <a href=\"/wiki/Legislature\" title=\"Legislature\">\n",
      "     Legislature\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <span class=\"nowrap\">\n",
      "     <a href=\"/wiki/Pennsylvania_General_Assembly\" title=\"Pennsylvania General Assembly\">\n",
      "      General Assembly\n",
      "     </a>\n",
      "    </span>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    •\n",
      "    <a href=\"/wiki/Upper_house\" title=\"Upper house\">\n",
      "     Upper house\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/Pennsylvania_State_Senate\" title=\"Pennsylvania State Senate\">\n",
      "     State Senate\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    •\n",
      "    <a href=\"/wiki/Lower_house\" title=\"Lower house\">\n",
      "     Lower house\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/Pennsylvania_House_of_Representatives\" title=\"Pennsylvania House of Representatives\">\n",
      "     House of Representatives\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    <a href=\"/wiki/Judiciary\" title=\"Judiciary\">\n",
      "     Judiciary\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/Supreme_Court_of_Pennsylvania\" title=\"Supreme Court of Pennsylvania\">\n",
      "     Supreme Court of Pennsylvania\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    <a href=\"/wiki/List_of_United_States_senators_from_Pennsylvania\" title=\"List of United States senators from Pennsylvania\">\n",
      "     U.S. senators\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <span class=\"nowrap\">\n",
      "     <a href=\"/wiki/Bob_Casey_Jr.\" title=\"Bob Casey Jr.\">\n",
      "      Bob Casey Jr.\n",
      "     </a>\n",
      "     (D)\n",
      "    </span>\n",
      "    <br/>\n",
      "    <span class=\"nowrap\">\n",
      "     <a href=\"/wiki/Pat_Toomey\" title=\"Pat Toomey\">\n",
      "      Pat Toomey\n",
      "     </a>\n",
      "     (\n",
      "     <a href=\"/wiki/Republican_Party_(United_States)\" title=\"Republican Party (United States)\">\n",
      "      R\n",
      "     </a>\n",
      "     )\n",
      "    </span>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    <a href=\"/wiki/United_States_House_of_Representatives\" title=\"United States House of Representatives\">\n",
      "     U.S. House delegation\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    9 Democrats\n",
      "    <br/>\n",
      "    9 Republicans (\n",
      "    <a href=\"/wiki/United_States_congressional_delegations_from_Pennsylvania\" title=\"United States congressional delegations from Pennsylvania\">\n",
      "     list\n",
      "    </a>\n",
      "    )\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th colspan=\"2\" style=\"text-align:center;text-align:left\">\n",
      "    Area\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "    </div>\n",
      "   </th>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Total\n",
      "   </th>\n",
      "   <td>\n",
      "    46,055 sq mi (119,283 km\n",
      "    <sup>\n",
      "     2\n",
      "    </sup>\n",
      "    )\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Land\n",
      "   </th>\n",
      "   <td>\n",
      "    44,816.61 sq mi (116,074 km\n",
      "    <sup>\n",
      "     2\n",
      "    </sup>\n",
      "    )\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Water\n",
      "   </th>\n",
      "   <td>\n",
      "    1,239 sq mi (3,208 km\n",
      "    <sup>\n",
      "     2\n",
      "    </sup>\n",
      "    )  2.7%\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    Area rank\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/List_of_U.S._states_and_territories_by_area\" title=\"List of U.S. states and territories by area\">\n",
      "     33rd\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th colspan=\"2\" style=\"text-align:center;text-align:left\">\n",
      "    Dimensions\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "    </div>\n",
      "   </th>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Length\n",
      "   </th>\n",
      "   <td>\n",
      "    170 mi (273 km)\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Width\n",
      "   </th>\n",
      "   <td>\n",
      "    283 mi (455 km)\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th scope=\"row\">\n",
      "    Elevation\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "    </div>\n",
      "   </th>\n",
      "   <td>\n",
      "    1,100 ft (340 m)\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    Highest elevation\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "     (\n",
      "     <a href=\"/wiki/Mount_Davis_(Pennsylvania)\" title=\"Mount Davis (Pennsylvania)\">\n",
      "      Mount Davis\n",
      "     </a>\n",
      "     <sup class=\"reference\" id=\"cite_ref-USGS_2-0\">\n",
      "      <a href=\"#cite_note-USGS-2\">\n",
      "       [2]\n",
      "      </a>\n",
      "     </sup>\n",
      "     <sup class=\"reference\" id=\"cite_ref-AVD88_3-0\">\n",
      "      <a href=\"#cite_note-AVD88-3\">\n",
      "       [3]\n",
      "      </a>\n",
      "     </sup>\n",
      "     )\n",
      "    </div>\n",
      "   </th>\n",
      "   <td>\n",
      "    3,213 ft (979 m)\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedbottomrow\">\n",
      "   <th scope=\"row\">\n",
      "    Lowest elevation\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "     (\n",
      "     <a href=\"/wiki/Delaware_River\" title=\"Delaware River\">\n",
      "      Delaware River\n",
      "     </a>\n",
      "     at\n",
      "     <span class=\"nowrap\">\n",
      "      <a href=\"/wiki/Delaware\" title=\"Delaware\">\n",
      "       Delaware\n",
      "      </a>\n",
      "      border\n",
      "     </span>\n",
      "     <sup class=\"reference\" id=\"cite_ref-USGS_2-1\">\n",
      "      <a href=\"#cite_note-USGS-2\">\n",
      "       [2]\n",
      "      </a>\n",
      "     </sup>\n",
      "     )\n",
      "    </div>\n",
      "   </th>\n",
      "   <td>\n",
      "    0 ft (0 m)\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th colspan=\"2\" style=\"text-align:center;text-align:left\">\n",
      "    Population\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "     <span class=\"nowrap\">\n",
      "     </span>\n",
      "     (2019)\n",
      "    </div>\n",
      "   </th>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Total\n",
      "   </th>\n",
      "   <td>\n",
      "    12,801,989\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Rank\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/List_of_states_and_territories_of_the_United_States_by_population\" title=\"List of states and territories of the United States by population\">\n",
      "     5th\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Density\n",
      "   </th>\n",
      "   <td>\n",
      "    284/sq mi (110/km\n",
      "    <sup>\n",
      "     2\n",
      "    </sup>\n",
      "    )\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Density rank\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/List_of_states_and_territories_of_the_United_States_by_population_density\" title=\"List of states and territories of the United States by population density\">\n",
      "     9th\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    •\n",
      "    <a href=\"/wiki/Household_income_in_the_United_States#Income_by_state\" title=\"Household income in the United States\">\n",
      "     Median household income\n",
      "    </a>\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "    </div>\n",
      "   </th>\n",
      "   <td>\n",
      "    $59,195\n",
      "    <sup class=\"reference\" id=\"cite_ref-4\">\n",
      "     <a href=\"#cite_note-4\">\n",
      "      [4]\n",
      "     </a>\n",
      "    </sup>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    • Income rank\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "    </div>\n",
      "   </th>\n",
      "   <td>\n",
      "    25th\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th scope=\"row\">\n",
      "    <a href=\"/wiki/Demonym\" title=\"Demonym\">\n",
      "     Demonym(s)\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    Pennsylvanian\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th colspan=\"2\" style=\"text-align:center;text-align:left\">\n",
      "    Language\n",
      "    <div style=\"font-weight:normal;display:inline;\">\n",
      "    </div>\n",
      "   </th>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    •\n",
      "    <a href=\"/wiki/Languages_of_the_United_States\" title=\"Languages of the United States\">\n",
      "     Official language\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    None\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    •\n",
      "    <a href=\"/wiki/Languages_of_the_United_States\" title=\"Languages of the United States\">\n",
      "     Spoken language\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/English_language\" title=\"English language\">\n",
      "     English\n",
      "    </a>\n",
      "    90.15%\n",
      "    <br/>\n",
      "    <a href=\"/wiki/Spanish_language\" title=\"Spanish language\">\n",
      "     Spanish\n",
      "    </a>\n",
      "    4.09%\n",
      "    <br/>\n",
      "    <a href=\"/wiki/German_language\" title=\"German language\">\n",
      "     German\n",
      "    </a>\n",
      "    (Including\n",
      "    <a href=\"/wiki/Pennsylvania_German_language\" title=\"Pennsylvania German language\">\n",
      "     Pennsylvania German\n",
      "    </a>\n",
      "    ) 0.87%\n",
      "    <br/>\n",
      "    <a href=\"/wiki/Chinese_language\" title=\"Chinese language\">\n",
      "     Chinese\n",
      "    </a>\n",
      "    0.47%\n",
      "    <br/>\n",
      "    <a href=\"/wiki/Italian_language\" title=\"Italian language\">\n",
      "     Italian\n",
      "    </a>\n",
      "    0.43%\n",
      "    <sup class=\"reference\" id=\"cite_ref-5\">\n",
      "     <a href=\"#cite_note-5\">\n",
      "      [5]\n",
      "     </a>\n",
      "    </sup>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th scope=\"row\">\n",
      "    <a href=\"/wiki/Time_zone\" title=\"Time zone\">\n",
      "     Time zone\n",
      "    </a>\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/UTC%E2%88%9205:00\" title=\"UTC−05:00\">\n",
      "     UTC−05:00\n",
      "    </a>\n",
      "    (\n",
      "    <a href=\"/wiki/Eastern_Time_Zone\" title=\"Eastern Time Zone\">\n",
      "     Eastern\n",
      "    </a>\n",
      "    )\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    <span style=\"white-space:nowrap\">\n",
      "     • Summer (\n",
      "     <a href=\"/wiki/Daylight_saving_time\" title=\"Daylight saving time\">\n",
      "      DST\n",
      "     </a>\n",
      "     )\n",
      "    </span>\n",
      "   </th>\n",
      "   <td>\n",
      "    <a href=\"/wiki/UTC%E2%88%9204:00\" title=\"UTC−04:00\">\n",
      "     UTC−04:00\n",
      "    </a>\n",
      "    (\n",
      "    <a class=\"mw-redirect\" href=\"/wiki/Eastern_Daylight_Time\" title=\"Eastern Daylight Time\">\n",
      "     EDT\n",
      "    </a>\n",
      "    )\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th scope=\"row\">\n",
      "    <a class=\"mw-redirect\" href=\"/wiki/List_of_U.S._state_abbreviations#Postal_codes\" title=\"List of U.S. state abbreviations\">\n",
      "     USPS abbreviation\n",
      "    </a>\n",
      "   </th>\n",
      "   <td class=\"adr\">\n",
      "    <div class=\"postal-code\">\n",
      "     PA\n",
      "    </div>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    <a href=\"/wiki/ISO_3166\" title=\"ISO 3166\">\n",
      "     ISO 3166 code\n",
      "    </a>\n",
      "   </th>\n",
      "   <td class=\"nickname\">\n",
      "    <a href=\"/wiki/ISO_3166-2:US\" title=\"ISO 3166-2:US\">\n",
      "     US-PA\n",
      "    </a>\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "   <th scope=\"row\">\n",
      "    <a class=\"mw-redirect\" href=\"/wiki/List_of_U.S._state_abbreviations#Current_use_of_traditional_abbreviations\" title=\"List of U.S. state abbreviations\">\n",
      "     Trad. abbreviation\n",
      "    </a>\n",
      "   </th>\n",
      "   <td class=\"nickname\">\n",
      "    Pa., Penn., Penna.\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th scope=\"row\">\n",
      "    Latitude\n",
      "   </th>\n",
      "   <td>\n",
      "    39°43′ to 42°16′ N\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedrow\">\n",
      "   <th scope=\"row\">\n",
      "    Longitude\n",
      "   </th>\n",
      "   <td>\n",
      "    74°41′ to 80°31′ W\n",
      "   </td>\n",
      "  </tr>\n",
      "  <tr class=\"mergedtoprow\">\n",
      "   <th scope=\"row\">\n",
      "    Website\n",
      "   </th>\n",
      "   <td>\n",
      "    <span class=\"url\">\n",
      "     <a class=\"external text\" href=\"https://www.pa.gov/\" rel=\"nofollow\">\n",
      "      www\n",
      "      <wbr/>\n",
      "      .pa\n",
      "      <wbr/>\n",
      "      .gov\n",
      "     </a>\n",
      "    </span>\n",
      "   </td>\n",
      "  </tr>\n",
      " </tbody>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('table').prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_table = soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pennsylvania'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find first table header \n",
    "first_table.find('th').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'State'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find first table data\n",
    "first_table.find('td').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pennsylvania'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find first table row\n",
    "first_table.find('tr').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaining methods and saving data in Python variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pennsylvania'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = soup.find('table').find('th').text\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pennsylvania\n",
      "State\n",
      "Commonwealth of Pennsylvania\n",
      "\n",
      "FlagSeal\n",
      "Nickname(s): Keystone State;[1] Quaker State\n",
      "Motto(s): Virtue, Liberty and Independence\n",
      "Anthem: \"Pennsylvania\"\n",
      "Map of the United States with Pennsylvania highlighted\n",
      "CountryUnited States\n",
      "Before statehoodProvince of Pennsylvania\n"
     ]
    }
   ],
   "source": [
    "for row in soup.find('table').find_all('tr')[:10]:\n",
    "    print(row.text)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locating information by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(text='Admitted') # nothing comes out, text search should be exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Admitted to the Union'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(text='Admitted to the Union')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could use RegularExpression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Admitted to the Union'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "admitted_regex = re.compile('Admitted')\n",
    "soup.find(text=admitted_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.NavigableString"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admitted = soup.find(text=admitted_regex)\n",
    "type(admitted) # because it is a BeautifulSoup element, we can navigate the DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>December 12, 1787 (2nd)</td>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admitted.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'December 12, 1787 (2nd)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admitted.next.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the Capital of Pennsylvania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Capital'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capital_regex = \"Capital\"\n",
    "soup.find(text=capital_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td><a href=\"/wiki/Harrisburg,_Pennsylvania\" title=\"Harrisburg, Pennsylvania\">Harrisburg</a></td>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capital = soup.find(text=capital_regex)\n",
    "capital.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrisburg'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capital.next.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the first three references (at the bottom of the page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref3 = soup.find(class_ = 'references').find_all('cite')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Symbols of Pennsylvania\". Portal.state.pa.us. Archived from the original on October 14, 2007. Retrieved May 4, 2014.\n",
      "\"Elevations and Distances in the United States\". United States Geological Survey. 2001. Archived from the original on October 15, 2011. Retrieved October 24, 2011.\n",
      "\"Median Annual Household Income\". The Henry J. Kaiser Family Foundation. Archived from the original on December 20, 2016. Retrieved December 9, 2016.\n"
     ]
    }
   ],
   "source": [
    "# print first 3 references\n",
    "for ref in ref3:\n",
    "    print(ref.text)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.portal.state.pa.us/portal/server.pt/community/things/4280/symbols_of_pennsylvania/478690\n",
      "https://web.archive.org/web/20071014215922/http://www.phmc.state.pa.us/bah/pahist/symbols.asp?secid=31\n",
      "https://web.archive.org/web/20111015012701/http://egsc.usgs.gov/isb/pubs/booklets/elvadist/elvadist.html\n",
      "http://egsc.usgs.gov/isb/pubs/booklets/elvadist/elvadist.html\n",
      "http://kff.org/other/state-indicator/median-annual-income/?currentTimeframe=0\n",
      "https://web.archive.org/web/20161220091007/http://kff.org/other/state-indicator/median-annual-income/?currentTimeframe=0\n"
     ]
    }
   ],
   "source": [
    "# print first 3 external links\n",
    "for ref in ref3:\n",
    "    for link in ref.find_all('a', class_ = 'external'):\n",
    "        print(link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Now that we know how to gather information from the web, what do we do with it?\n",
    "\n",
    "This data can be\n",
    "\n",
    "* aggregated to look for trends\n",
    "* visualized to understand patterns\n",
    "* leveraged with machine learning algorithms\n",
    "But first we need to\n",
    "\n",
    "* convert several strings into numerical or datetime values\n",
    "* collect and store data from multiple pages (next section)\n",
    "\n",
    "**Tip:** Most web scraping project rely on multiple pages of information, each of which serving as a data observation. For this case, we might collect data about Pennsylvania and then collect the same kinds of information for all 50 United States before analyzing or visualizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "#### Date Admitted\n",
    "In the last section, we collected the date that Pennsylvania was admitted to the union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'December 12, 1787 (2nd)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admitted_date = admitted.next.text\n",
    "admitted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['December', '12,', '1787']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the string\n",
    "admitted_date_list = admitted_date.split(' ')[:-1]\n",
    "admitted_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'December 12, 1787'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the list\n",
    "admitted_date_str = ' '.join(admitted_date_list)\n",
    "admitted_date_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert this string into a datetime data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1787, 12, 12, 0, 0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_admitted = dateutil.parser.parse(admitted_date_str)\n",
    "date_admitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(date_admitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1787"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_admitted.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population and Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xa0•\\xa0Total'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(text=re.compile('Total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>46,055 sq mi (119,283 km<sup>2</sup>)</td>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(text=re.compile('Total')).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46,055\\xa0sq\\xa0mi (119,283\\xa0km2)'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save area text in a variable\n",
    "area_text = soup.find(text=re.compile('Total')).next.text\n",
    "area_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr class=\"mergedtoprow\"><th colspan=\"2\" style=\"text-align:center;text-align:left\">Population<div style=\"font-weight:normal;display:inline;\"><span class=\"nowrap\"> </span>(2019)</div></th></tr>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(text=re.compile('Population')).parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr class=\"mergedrow\"><th scope=\"row\"> • Total</th><td>12,801,989</td></tr>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(text=re.compile('Population')).parent.parent.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>12,801,989</td>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(text=re.compile('Population')).parent.parent.next_sibling.find('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12,801,989'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_text = soup.find(text=re.compile('Population')).parent.parent.next_sibling.find('td').text\n",
    "population_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert strings into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12801989"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = int(population_text.replace(',', ''))\n",
    "\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create converter functions\n",
    "\n",
    "def to_date(date_str):\n",
    "    date_str = re.match('[\\w\\s,]+', date_str)[0]\n",
    "    return dateutil.parser.parse(date_str)\n",
    "\n",
    "def to_int(number_str):\n",
    "    number_str = re.match('[\\d,$]+', number_str)[0]\n",
    "    number_str = number_str.replace('$', '').replace(',', '')\n",
    "    return int(number_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46055"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area = to_int(area_text)\n",
    "area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data storage\n",
    "Now let's put all the information we have about Pennsylvania together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'Pennsylvania',\n",
       " 'date_admitted': datetime.datetime(1787, 12, 12, 0, 0),\n",
       " 'population': 12801989,\n",
       " 'area_sq_mi': 46055}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penn_dict=  {\n",
    "    'state': state, \n",
    "    'date_admitted': date_admitted,\n",
    "    'population': population,\n",
    "    'area_sq_mi': area\n",
    "}\n",
    "penn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have this information in dictionary form, we can build a pandas dataframe with it and eventually perform further analyses or save it to our computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_info = [penn_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date_admitted</th>\n",
       "      <th>population</th>\n",
       "      <th>area_sq_mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1787-12-12</td>\n",
       "      <td>12801989</td>\n",
       "      <td>46055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          state date_admitted  population  area_sq_mi\n",
       "0  Pennsylvania    1787-12-12    12801989       46055"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penn_df = pd.DataFrame(penn_info)\n",
    "penn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to a csv\n",
    "penn_df.to_csv('Penn_State_Information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$59,195[4]'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find median household income\n",
    "mhi_text =soup.find(text='Median household income').next.next.text\n",
    "mhi_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59195"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhi = to_int(mhi_text)\n",
    "mhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'Pennsylvania',\n",
       " 'date_admitted': datetime.datetime(1787, 12, 12, 0, 0),\n",
       " 'population': 12801989,\n",
       " 'area_sq_mi': 46055,\n",
       " 'median_household_income': 59195}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add mhi to state dict\n",
    "penn_dict['median_household_income'] = mhi\n",
    "penn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date_admitted</th>\n",
       "      <th>population</th>\n",
       "      <th>area_sq_mi</th>\n",
       "      <th>median_household_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1787-12-12</td>\n",
       "      <td>12801989</td>\n",
       "      <td>46055</td>\n",
       "      <td>59195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          state date_admitted  population  area_sq_mi  median_household_income\n",
       "0  Pennsylvania    1787-12-12    12801989       46055                    59195"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recreate the dataframe\n",
    "state_df = pd.DataFrame([penn_dict])\n",
    "state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Considerations\n",
    "Now that we can extract numerical data from this page about Pennsylvania, how would we build out a full analytic or data science project?\n",
    "\n",
    "The next step is to systematically retrieve this information from the Wikipedia page of each US state. First, let's build reusable functions to find the state's\n",
    "\n",
    "* name\n",
    "* date admitted\n",
    "* population\n",
    "* area\n",
    "* median household income\n",
    "\n",
    "Note: all of this info can be found in the table on the right side of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(table):\n",
    "    raw_name = table.find('th').text\n",
    "    return re.match('[A-z\\s]+', raw_name)[0]\n",
    "\n",
    "def get_date_admitted(table):\n",
    "    raw_date = table.find(text='Admitted to the Union').next.text\n",
    "    return to_date(raw_date)\n",
    "\n",
    "def get_population(table):\n",
    "    raw_population = table.find(text='Population')\\\n",
    "        .parent.parent.next_sibling.find('td').text\n",
    "    return to_int(raw_population)\n",
    "\n",
    "def get_area(table):\n",
    "    raw_area = table.find(text=re.compile('Total')).next.text\n",
    "    return to_int(raw_area)\n",
    "\n",
    "def get_income(table):\n",
    "    raw_income = table.find(text='Median household income').next.next.text\n",
    "    return to_int(raw_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions will extract information from any Wikipedia state table we pass into them. For example, let's try parsing the page for New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_url = 'https://en.wikipedia.org/wiki/New_York_(state)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_page = requests.get(ny_url).text\n",
    "ny_soup = bs(ny_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_table = ny_soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name(ny_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19453561"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_population(ny_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54555"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_area(ny_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1788, 7, 26, 0, 0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_date_admitted(ny_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64894"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_income(ny_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make a function to gather all five values from a given state Wiki page and return the information as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url(url):\n",
    "    page = requests.get(url).text\n",
    "    return bs(page)\n",
    "\n",
    "def get_state_info(state_url):\n",
    "    \n",
    "    #parse url with above function and get table\n",
    "    state_soup = parse_url(state_url)\n",
    "    state_table = state_soup.find('table')\n",
    "    \n",
    "    state_info = {}\n",
    "    \n",
    "    #get info with pre-defined functions\n",
    "    state_info['state'] = get_name(state_table)\n",
    "    state_info['date_admitted'] = get_date_admitted(state_table)\n",
    "    state_info['population'] = get_population(state_table)\n",
    "    state_info['area'] = get_area(state_table)\n",
    "    state_info['median_household_income'] = get_income(state_table)\n",
    "    \n",
    "    return state_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'New York',\n",
       " 'date_admitted': datetime.datetime(1788, 7, 26, 0, 0),\n",
       " 'population': 19453561,\n",
       " 'area': 54555,\n",
       " 'median_household_income': 64894}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_info = get_state_info(ny_url)\n",
    "ny_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of links\n",
    "The next step in our process will require us to use our get_state_info() function on the URLs of each of the 50 US states. But how do we know which URLs to visit? We might be able to guess that the page for Rhode Island is https://en.wikipedia.org/wiki/Rhode_Island but not all pages follow this convention.\n",
    "\n",
    "Instead of guessing, let's first gather these links from this \"[List of States and Territories of the United States\" article](https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States).\n",
    "\n",
    "Click on this link and inspect the page to develop a plan for doing this.\n",
    "\n",
    "It looks like each of the states are listed in the second table of the page. Each state name and link is contained within table header tags (th) and have the additional property of scope=\"row\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_url = 'https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States'\n",
    "list_page = requests.get(list_url).text\n",
    "list_soup = bs(list_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<th scope=\"row\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"400\" data-file-width=\"600\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Flag_of_Alabama.svg/23px-Flag_of_Alabama.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Flag_of_Alabama.svg/35px-Flag_of_Alabama.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Flag_of_Alabama.svg/45px-Flag_of_Alabama.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Alabama\" title=\"Alabama\">Alabama</a>\n",
       " </th>,\n",
       " <th scope=\"row\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"1000\" data-file-width=\"1416\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Flag_of_Alaska.svg/21px-Flag_of_Alaska.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Flag_of_Alaska.svg/33px-Flag_of_Alaska.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Flag_of_Alaska.svg/43px-Flag_of_Alaska.svg.png 2x\" width=\"21\"/> </span><a href=\"/wiki/Alaska\" title=\"Alaska\">Alaska</a>\n",
       " </th>,\n",
       " <th scope=\"row\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Flag_of_Arizona.svg/23px-Flag_of_Arizona.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Flag_of_Arizona.svg/35px-Flag_of_Arizona.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Flag_of_Arizona.svg/45px-Flag_of_Arizona.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Arizona\" title=\"Arizona\">Arizona</a>\n",
       " </th>,\n",
       " <th scope=\"row\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"300\" data-file-width=\"450\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Flag_of_Arkansas.svg/23px-Flag_of_Arkansas.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Flag_of_Arkansas.svg/35px-Flag_of_Arkansas.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Flag_of_Arkansas.svg/45px-Flag_of_Arkansas.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Arkansas\" title=\"Arkansas\">Arkansas</a>\n",
       " </th>,\n",
       " <th scope=\"row\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/01/Flag_of_California.svg/23px-Flag_of_California.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/01/Flag_of_California.svg/35px-Flag_of_California.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/01/Flag_of_California.svg/45px-Flag_of_California.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/California\" title=\"California\">California</a>\n",
       " </th>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_rows = list_soup.find_all('table')[0].find_all('th', scope='row')\n",
    "state_rows[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/wiki/Alabama\" title=\"Alabama\">Alabama</a>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_rows[0].find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wiki/Alabama'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_rows[0].find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Alabama',\n",
       " '/wiki/Alaska',\n",
       " '/wiki/Arizona',\n",
       " '/wiki/Arkansas',\n",
       " '/wiki/California']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_links  = [row.find('a')['href'] for row in state_rows]\n",
    "state_links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these links point to a place within Wikipedia, but if we want to link to the full URLs, we have to append 'https://en.wikipedia.org' to each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Alabama',\n",
       " 'https://en.wikipedia.org/wiki/Alaska',\n",
       " 'https://en.wikipedia.org/wiki/Arizona',\n",
       " 'https://en.wikipedia.org/wiki/Arkansas',\n",
       " 'https://en.wikipedia.org/wiki/California']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://en.wikipedia.org'\n",
    "state_urls = [base_url + link for link in state_links]\n",
    "state_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Virginia',\n",
       " 'https://en.wikipedia.org/wiki/Washington_(state)',\n",
       " 'https://en.wikipedia.org/wiki/West_Virginia',\n",
       " 'https://en.wikipedia.org/wiki/Wisconsin',\n",
       " 'https://en.wikipedia.org/wiki/Wyoming']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_urls[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "We will eventually be cycling through these state links to collect and store information about every state. But what happens when certain information is unavailable? That is, what if the Georgia page is missing area information or the median household income isn't listed for Nevada?\n",
    "\n",
    "We can make our code more robust by including instructions for handling missing information. One way to do this is to include try/except statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_info_robust(state_url):\n",
    "    #if we can't find the url, we print out the url and exit the page\n",
    "    try:\n",
    "        state_soup = parse_url(state_url)\n",
    "        state_table = state_soup.find('table')\n",
    "    except:\n",
    "        print(f\"Cannot parse table: {state_url}\")\n",
    "        return None\n",
    "    \n",
    "    state_info = {}\n",
    "    \n",
    "    # granb info with pre-defined functions\n",
    "    # if any values can't be found, fill with None\n",
    "    values = ['state', 'date_admitted', 'population', 'area_sq_mi', 'median_household_income']\n",
    "    functions = [get_name, get_date_admitted, get_population, get_area, get_income]\n",
    "    \n",
    "    for val, func in zip(values,functions):\n",
    "        try:\n",
    "            state_info[val]=func(state_table)\n",
    "        except:\n",
    "            state_info[val] = None\n",
    "    \n",
    "    return state_info\n",
    "              \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'New York',\n",
       " 'date_admitted': datetime.datetime(1788, 7, 26, 0, 0),\n",
       " 'population': 19453561,\n",
       " 'area_sq_mi': 54555,\n",
       " 'median_household_income': 64894}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_dict = get_state_info_robust(ny_url)\n",
    "ny_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'Year\\n',\n",
       " 'date_admitted': None,\n",
       " 'population': None,\n",
       " 'area_sq_mi': None,\n",
       " 'median_household_income': None}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_state_info_robust('https://en.wikipedia.org/wiki/Python_Conference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot parse table: https://notawebsiteatleastihopenot.net\n"
     ]
    }
   ],
   "source": [
    "get_state_info_robust('https://notawebsiteatleastihopenot.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding pauses\n",
    "We have just one final consideration before we cycle through the state links to scrape information. Web scraping at a fast rate--that is, many pages per second--is frowned upon by many websites, Wikipedia included. We will add in artificial pauses so we don't overwhelm the Wikipedia server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pausing for 5 seconds\n",
      "b equals 6\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "\n",
    "print(f\"Pausing for {a} seconds\")\n",
    "time.sleep(a)\n",
    "\n",
    "b = a + 1\n",
    "print(f\"b equals {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To responsibly scrape websites, you should know what the site's rate limit is and respect it! Most sites list their rate limit for web scraping in their robots.txt file. More on this later.\n",
    "\n",
    "Wikipedia [ at least a one second pause per page request](https://en.wikipedia.org/wiki/Wikipedia:Database_download#Please_do_not_use_a_web_crawler). We will pause 1 second between each page scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data storage revisited\n",
    "We now have a function to extract information for each state as a dictionary. We can convert this information into a pandas dataframe and store it to an Excel or .csv file if we pass in a list of dictionaries, all with the same keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date_admitted</th>\n",
       "      <th>population</th>\n",
       "      <th>area_sq_mi</th>\n",
       "      <th>median_household_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1787-12-12</td>\n",
       "      <td>12801989</td>\n",
       "      <td>46055</td>\n",
       "      <td>59195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>1788-07-26</td>\n",
       "      <td>19453561</td>\n",
       "      <td>54555</td>\n",
       "      <td>64894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          state date_admitted  population  area_sq_mi  median_household_income\n",
       "0  Pennsylvania    1787-12-12    12801989       46055                    59195\n",
       "1      New York    1788-07-26    19453561       54555                    64894"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([penn_dict, ny_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build out our full pipeline:\n",
    "\n",
    "1. Gather a list of links to each state. (DONE)\n",
    "2. For each state link, gather state information as a dictionary.\n",
    "3. Append each state dictionary to a list.\n",
    "4. Convert list of dictionaries to dataframe.\n",
    "5. Save dataframe as a .csv or an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_info_list = []\n",
    "\n",
    "for link in state_urls:\n",
    "    # step 2\n",
    "    state_info = get_state_info_robust(link)\n",
    "    \n",
    "    # step 3\n",
    "    if state_info:\n",
    "        state_info_list.append(state_info)\n",
    "        \n",
    "    # pause\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 'Alabama',\n",
       "  'date_admitted': datetime.datetime(1819, 12, 14, 0, 0),\n",
       "  'population': 4903185,\n",
       "  'area_sq_mi': 52419,\n",
       "  'median_household_income': 48123},\n",
       " {'state': 'AlaskaAlax',\n",
       "  'date_admitted': datetime.datetime(1959, 1, 3, 0, 0),\n",
       "  'population': 710249,\n",
       "  'area_sq_mi': 663268,\n",
       "  'median_household_income': 73181},\n",
       " {'state': 'Arizona',\n",
       "  'date_admitted': datetime.datetime(1912, 2, 14, 0, 0),\n",
       "  'population': 7278717,\n",
       "  'area_sq_mi': 113990,\n",
       "  'median_household_income': 56581},\n",
       " {'state': 'Arkansas',\n",
       "  'date_admitted': datetime.datetime(1836, 6, 15, 0, 0),\n",
       "  'population': 3017804,\n",
       "  'area_sq_mi': 53179,\n",
       "  'median_household_income': 45869},\n",
       " {'state': 'California',\n",
       "  'date_admitted': datetime.datetime(1850, 9, 9, 0, 0),\n",
       "  'population': 39512223,\n",
       "  'area_sq_mi': 163696,\n",
       "  'median_household_income': 71228}]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_info_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date_admitted</th>\n",
       "      <th>population</th>\n",
       "      <th>area_sq_mi</th>\n",
       "      <th>median_household_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1819-12-14</td>\n",
       "      <td>4903185</td>\n",
       "      <td>52419</td>\n",
       "      <td>48123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlaskaAlax</td>\n",
       "      <td>1959-01-03</td>\n",
       "      <td>710249</td>\n",
       "      <td>663268</td>\n",
       "      <td>73181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>1912-02-14</td>\n",
       "      <td>7278717</td>\n",
       "      <td>113990</td>\n",
       "      <td>56581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1836-06-15</td>\n",
       "      <td>3017804</td>\n",
       "      <td>53179</td>\n",
       "      <td>45869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>1850-09-09</td>\n",
       "      <td>39512223</td>\n",
       "      <td>163696</td>\n",
       "      <td>71228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>1876-08-01</td>\n",
       "      <td>5758736</td>\n",
       "      <td>104094</td>\n",
       "      <td>69117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1788-01-09</td>\n",
       "      <td>3565287</td>\n",
       "      <td>5567</td>\n",
       "      <td>76106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>1787-12-07</td>\n",
       "      <td>982895</td>\n",
       "      <td>1982</td>\n",
       "      <td>62852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florida</td>\n",
       "      <td>1845-03-03</td>\n",
       "      <td>21477737</td>\n",
       "      <td>65757</td>\n",
       "      <td>53267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>1788-01-02</td>\n",
       "      <td>10617423</td>\n",
       "      <td>59425</td>\n",
       "      <td>56183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HawaiiMoku</td>\n",
       "      <td>1959-08-21</td>\n",
       "      <td>1415872</td>\n",
       "      <td>10931</td>\n",
       "      <td>77765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>1890-07-03</td>\n",
       "      <td>1787065</td>\n",
       "      <td>83569</td>\n",
       "      <td>52225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>1818-12-03</td>\n",
       "      <td>12671821</td>\n",
       "      <td>57915</td>\n",
       "      <td>65030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>1816-12-11</td>\n",
       "      <td>6732219</td>\n",
       "      <td>36418</td>\n",
       "      <td>54181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>1846-12-27</td>\n",
       "      <td>3155070</td>\n",
       "      <td>58295</td>\n",
       "      <td>59955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2913314</td>\n",
       "      <td>82278</td>\n",
       "      <td>56422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1792-06-01</td>\n",
       "      <td>4467673</td>\n",
       "      <td>40408</td>\n",
       "      <td>48375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>1812-04-30</td>\n",
       "      <td>4648794</td>\n",
       "      <td>52069</td>\n",
       "      <td>49973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maine</td>\n",
       "      <td>1820-03-15</td>\n",
       "      <td>1344212</td>\n",
       "      <td>35385</td>\n",
       "      <td>56277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>1788-04-28</td>\n",
       "      <td>6045680</td>\n",
       "      <td>12407</td>\n",
       "      <td>80776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1788-02-06</td>\n",
       "      <td>6892503</td>\n",
       "      <td>10565</td>\n",
       "      <td>77385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>1837-01-26</td>\n",
       "      <td>9883635</td>\n",
       "      <td>96716</td>\n",
       "      <td>54909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>1858-05-11</td>\n",
       "      <td>5639632</td>\n",
       "      <td>86950</td>\n",
       "      <td>68388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1817-12-10</td>\n",
       "      <td>2976149</td>\n",
       "      <td>48430</td>\n",
       "      <td>43567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>1821-08-10</td>\n",
       "      <td>6137428</td>\n",
       "      <td>69715</td>\n",
       "      <td>53578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Montana</td>\n",
       "      <td>1889-11-08</td>\n",
       "      <td>1068778</td>\n",
       "      <td>147040</td>\n",
       "      <td>53386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>1867-03-01</td>\n",
       "      <td>1934408</td>\n",
       "      <td>77358</td>\n",
       "      <td>59970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>1864-10-31</td>\n",
       "      <td>3080156</td>\n",
       "      <td>110577</td>\n",
       "      <td>58003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>1788-06-21</td>\n",
       "      <td>1359711</td>\n",
       "      <td>9349</td>\n",
       "      <td>73381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1787-12-18</td>\n",
       "      <td>8882190</td>\n",
       "      <td>8722</td>\n",
       "      <td>79363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>1912-01-06</td>\n",
       "      <td>2096829</td>\n",
       "      <td>121590</td>\n",
       "      <td>46744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New York</td>\n",
       "      <td>1788-07-26</td>\n",
       "      <td>19453561</td>\n",
       "      <td>54555</td>\n",
       "      <td>64894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1789-11-21</td>\n",
       "      <td>10488084</td>\n",
       "      <td>53819</td>\n",
       "      <td>52752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1889-11-02</td>\n",
       "      <td>762062</td>\n",
       "      <td>70761</td>\n",
       "      <td>61843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>1803-03-01</td>\n",
       "      <td>11689100</td>\n",
       "      <td>44825</td>\n",
       "      <td>54021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>1907-11-16</td>\n",
       "      <td>3956971</td>\n",
       "      <td>69899</td>\n",
       "      <td>50051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>1859-02-14</td>\n",
       "      <td>4217737</td>\n",
       "      <td>98381</td>\n",
       "      <td>60212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1787-12-12</td>\n",
       "      <td>12801989</td>\n",
       "      <td>46055</td>\n",
       "      <td>59195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>1790-05-29</td>\n",
       "      <td>1059361</td>\n",
       "      <td>1214</td>\n",
       "      <td>63870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>1788-05-23</td>\n",
       "      <td>5148714</td>\n",
       "      <td>32020</td>\n",
       "      <td>50570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>1889-11-02</td>\n",
       "      <td>884659</td>\n",
       "      <td>77116</td>\n",
       "      <td>56521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1796-06-01</td>\n",
       "      <td>6829174</td>\n",
       "      <td>42143</td>\n",
       "      <td>52340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Texas</td>\n",
       "      <td>1845-12-29</td>\n",
       "      <td>28995881</td>\n",
       "      <td>268596</td>\n",
       "      <td>59206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Utah</td>\n",
       "      <td>1896-01-04</td>\n",
       "      <td>3205958</td>\n",
       "      <td>84899</td>\n",
       "      <td>68374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>1791-03-04</td>\n",
       "      <td>623989</td>\n",
       "      <td>9616</td>\n",
       "      <td>57513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>1788-06-25</td>\n",
       "      <td>8535519</td>\n",
       "      <td>42774</td>\n",
       "      <td>71535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Washington</td>\n",
       "      <td>1889-11-11</td>\n",
       "      <td>7614893</td>\n",
       "      <td>71362</td>\n",
       "      <td>70979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1863-06-20</td>\n",
       "      <td>1792147</td>\n",
       "      <td>24230</td>\n",
       "      <td>43469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1848-05-29</td>\n",
       "      <td>5822434</td>\n",
       "      <td>65498</td>\n",
       "      <td>59305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1890-07-10</td>\n",
       "      <td>578759</td>\n",
       "      <td>97914</td>\n",
       "      <td>62268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state date_admitted  population  area_sq_mi  \\\n",
       "0          Alabama    1819-12-14     4903185       52419   \n",
       "1       AlaskaAlax    1959-01-03      710249      663268   \n",
       "2          Arizona    1912-02-14     7278717      113990   \n",
       "3         Arkansas    1836-06-15     3017804       53179   \n",
       "4       California    1850-09-09    39512223      163696   \n",
       "5         Colorado    1876-08-01     5758736      104094   \n",
       "6      Connecticut    1788-01-09     3565287        5567   \n",
       "7         Delaware    1787-12-07      982895        1982   \n",
       "8          Florida    1845-03-03    21477737       65757   \n",
       "9          Georgia    1788-01-02    10617423       59425   \n",
       "10      HawaiiMoku    1959-08-21     1415872       10931   \n",
       "11           Idaho    1890-07-03     1787065       83569   \n",
       "12        Illinois    1818-12-03    12671821       57915   \n",
       "13         Indiana    1816-12-11     6732219       36418   \n",
       "14            Iowa    1846-12-27     3155070       58295   \n",
       "15          Kansas           NaT     2913314       82278   \n",
       "16        Kentucky    1792-06-01     4467673       40408   \n",
       "17       Louisiana    1812-04-30     4648794       52069   \n",
       "18           Maine    1820-03-15     1344212       35385   \n",
       "19        Maryland    1788-04-28     6045680       12407   \n",
       "20   Massachusetts    1788-02-06     6892503       10565   \n",
       "21        Michigan    1837-01-26     9883635       96716   \n",
       "22       Minnesota    1858-05-11     5639632       86950   \n",
       "23     Mississippi    1817-12-10     2976149       48430   \n",
       "24        Missouri    1821-08-10     6137428       69715   \n",
       "25         Montana    1889-11-08     1068778      147040   \n",
       "26        Nebraska    1867-03-01     1934408       77358   \n",
       "27          Nevada    1864-10-31     3080156      110577   \n",
       "28   New Hampshire    1788-06-21     1359711        9349   \n",
       "29      New Jersey    1787-12-18     8882190        8722   \n",
       "30      New Mexico    1912-01-06     2096829      121590   \n",
       "31        New York    1788-07-26    19453561       54555   \n",
       "32  North Carolina    1789-11-21    10488084       53819   \n",
       "33    North Dakota    1889-11-02      762062       70761   \n",
       "34            Ohio    1803-03-01    11689100       44825   \n",
       "35        Oklahoma    1907-11-16     3956971       69899   \n",
       "36          Oregon    1859-02-14     4217737       98381   \n",
       "37    Pennsylvania    1787-12-12    12801989       46055   \n",
       "38    Rhode Island    1790-05-29     1059361        1214   \n",
       "39  South Carolina    1788-05-23     5148714       32020   \n",
       "40    South Dakota    1889-11-02      884659       77116   \n",
       "41       Tennessee    1796-06-01     6829174       42143   \n",
       "42           Texas    1845-12-29    28995881      268596   \n",
       "43            Utah    1896-01-04     3205958       84899   \n",
       "44         Vermont    1791-03-04      623989        9616   \n",
       "45        Virginia    1788-06-25     8535519       42774   \n",
       "46      Washington    1889-11-11     7614893       71362   \n",
       "47   West Virginia    1863-06-20     1792147       24230   \n",
       "48       Wisconsin    1848-05-29     5822434       65498   \n",
       "49         Wyoming    1890-07-10      578759       97914   \n",
       "\n",
       "    median_household_income  \n",
       "0                     48123  \n",
       "1                     73181  \n",
       "2                     56581  \n",
       "3                     45869  \n",
       "4                     71228  \n",
       "5                     69117  \n",
       "6                     76106  \n",
       "7                     62852  \n",
       "8                     53267  \n",
       "9                     56183  \n",
       "10                    77765  \n",
       "11                    52225  \n",
       "12                    65030  \n",
       "13                    54181  \n",
       "14                    59955  \n",
       "15                    56422  \n",
       "16                    48375  \n",
       "17                    49973  \n",
       "18                    56277  \n",
       "19                    80776  \n",
       "20                    77385  \n",
       "21                    54909  \n",
       "22                    68388  \n",
       "23                    43567  \n",
       "24                    53578  \n",
       "25                    53386  \n",
       "26                    59970  \n",
       "27                    58003  \n",
       "28                    73381  \n",
       "29                    79363  \n",
       "30                    46744  \n",
       "31                    64894  \n",
       "32                    52752  \n",
       "33                    61843  \n",
       "34                    54021  \n",
       "35                    50051  \n",
       "36                    60212  \n",
       "37                    59195  \n",
       "38                    63870  \n",
       "39                    50570  \n",
       "40                    56521  \n",
       "41                    52340  \n",
       "42                    59206  \n",
       "43                    68374  \n",
       "44                    57513  \n",
       "45                    71535  \n",
       "46                    70979  \n",
       "47                    43469  \n",
       "48                    59305  \n",
       "49                    62268  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 4\n",
    "state_data = pd.DataFrame(state_info_list)\n",
    "state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15   NaT\n",
       "Name: date_admitted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kansas date_admitted to Union is invalid\n",
    "state_data.loc[(state_data.state == 'Kansas'),'date_admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15   1861-01-29\n",
       "Name: date_admitted, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the panda data frame with correct admitted date\n",
    "state_data.loc[(state_data.state == 'Kansas'),'date_admitted'] = to_date('January 29, 1861')\n",
    "state_data.loc[(state_data.state == 'Kansas'),'date_admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AlaskaAlax'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alaska's name is in correct\n",
    "state_data.iloc[1].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting state name for Alaska\n",
    "state_data.loc[(state_data.state == 'AlaskaAlax'),'state'] = 'Alaska'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alaska'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_data.iloc[1].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date_admitted</th>\n",
       "      <th>population</th>\n",
       "      <th>area_sq_mi</th>\n",
       "      <th>median_household_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1819-12-14</td>\n",
       "      <td>4903185</td>\n",
       "      <td>52419</td>\n",
       "      <td>48123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>1959-01-03</td>\n",
       "      <td>710249</td>\n",
       "      <td>663268</td>\n",
       "      <td>73181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>1912-02-14</td>\n",
       "      <td>7278717</td>\n",
       "      <td>113990</td>\n",
       "      <td>56581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1836-06-15</td>\n",
       "      <td>3017804</td>\n",
       "      <td>53179</td>\n",
       "      <td>45869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>1850-09-09</td>\n",
       "      <td>39512223</td>\n",
       "      <td>163696</td>\n",
       "      <td>71228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>1876-08-01</td>\n",
       "      <td>5758736</td>\n",
       "      <td>104094</td>\n",
       "      <td>69117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1788-01-09</td>\n",
       "      <td>3565287</td>\n",
       "      <td>5567</td>\n",
       "      <td>76106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>1787-12-07</td>\n",
       "      <td>982895</td>\n",
       "      <td>1982</td>\n",
       "      <td>62852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florida</td>\n",
       "      <td>1845-03-03</td>\n",
       "      <td>21477737</td>\n",
       "      <td>65757</td>\n",
       "      <td>53267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>1788-01-02</td>\n",
       "      <td>10617423</td>\n",
       "      <td>59425</td>\n",
       "      <td>56183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HawaiiMoku</td>\n",
       "      <td>1959-08-21</td>\n",
       "      <td>1415872</td>\n",
       "      <td>10931</td>\n",
       "      <td>77765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>1890-07-03</td>\n",
       "      <td>1787065</td>\n",
       "      <td>83569</td>\n",
       "      <td>52225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>1818-12-03</td>\n",
       "      <td>12671821</td>\n",
       "      <td>57915</td>\n",
       "      <td>65030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>1816-12-11</td>\n",
       "      <td>6732219</td>\n",
       "      <td>36418</td>\n",
       "      <td>54181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>1846-12-27</td>\n",
       "      <td>3155070</td>\n",
       "      <td>58295</td>\n",
       "      <td>59955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>1861-01-29</td>\n",
       "      <td>2913314</td>\n",
       "      <td>82278</td>\n",
       "      <td>56422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1792-06-01</td>\n",
       "      <td>4467673</td>\n",
       "      <td>40408</td>\n",
       "      <td>48375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>1812-04-30</td>\n",
       "      <td>4648794</td>\n",
       "      <td>52069</td>\n",
       "      <td>49973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maine</td>\n",
       "      <td>1820-03-15</td>\n",
       "      <td>1344212</td>\n",
       "      <td>35385</td>\n",
       "      <td>56277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>1788-04-28</td>\n",
       "      <td>6045680</td>\n",
       "      <td>12407</td>\n",
       "      <td>80776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1788-02-06</td>\n",
       "      <td>6892503</td>\n",
       "      <td>10565</td>\n",
       "      <td>77385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>1837-01-26</td>\n",
       "      <td>9883635</td>\n",
       "      <td>96716</td>\n",
       "      <td>54909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>1858-05-11</td>\n",
       "      <td>5639632</td>\n",
       "      <td>86950</td>\n",
       "      <td>68388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1817-12-10</td>\n",
       "      <td>2976149</td>\n",
       "      <td>48430</td>\n",
       "      <td>43567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>1821-08-10</td>\n",
       "      <td>6137428</td>\n",
       "      <td>69715</td>\n",
       "      <td>53578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Montana</td>\n",
       "      <td>1889-11-08</td>\n",
       "      <td>1068778</td>\n",
       "      <td>147040</td>\n",
       "      <td>53386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>1867-03-01</td>\n",
       "      <td>1934408</td>\n",
       "      <td>77358</td>\n",
       "      <td>59970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>1864-10-31</td>\n",
       "      <td>3080156</td>\n",
       "      <td>110577</td>\n",
       "      <td>58003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>1788-06-21</td>\n",
       "      <td>1359711</td>\n",
       "      <td>9349</td>\n",
       "      <td>73381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1787-12-18</td>\n",
       "      <td>8882190</td>\n",
       "      <td>8722</td>\n",
       "      <td>79363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>1912-01-06</td>\n",
       "      <td>2096829</td>\n",
       "      <td>121590</td>\n",
       "      <td>46744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New York</td>\n",
       "      <td>1788-07-26</td>\n",
       "      <td>19453561</td>\n",
       "      <td>54555</td>\n",
       "      <td>64894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1789-11-21</td>\n",
       "      <td>10488084</td>\n",
       "      <td>53819</td>\n",
       "      <td>52752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1889-11-02</td>\n",
       "      <td>762062</td>\n",
       "      <td>70761</td>\n",
       "      <td>61843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>1803-03-01</td>\n",
       "      <td>11689100</td>\n",
       "      <td>44825</td>\n",
       "      <td>54021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>1907-11-16</td>\n",
       "      <td>3956971</td>\n",
       "      <td>69899</td>\n",
       "      <td>50051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>1859-02-14</td>\n",
       "      <td>4217737</td>\n",
       "      <td>98381</td>\n",
       "      <td>60212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1787-12-12</td>\n",
       "      <td>12801989</td>\n",
       "      <td>46055</td>\n",
       "      <td>59195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>1790-05-29</td>\n",
       "      <td>1059361</td>\n",
       "      <td>1214</td>\n",
       "      <td>63870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>1788-05-23</td>\n",
       "      <td>5148714</td>\n",
       "      <td>32020</td>\n",
       "      <td>50570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>1889-11-02</td>\n",
       "      <td>884659</td>\n",
       "      <td>77116</td>\n",
       "      <td>56521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1796-06-01</td>\n",
       "      <td>6829174</td>\n",
       "      <td>42143</td>\n",
       "      <td>52340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Texas</td>\n",
       "      <td>1845-12-29</td>\n",
       "      <td>28995881</td>\n",
       "      <td>268596</td>\n",
       "      <td>59206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Utah</td>\n",
       "      <td>1896-01-04</td>\n",
       "      <td>3205958</td>\n",
       "      <td>84899</td>\n",
       "      <td>68374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>1791-03-04</td>\n",
       "      <td>623989</td>\n",
       "      <td>9616</td>\n",
       "      <td>57513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>1788-06-25</td>\n",
       "      <td>8535519</td>\n",
       "      <td>42774</td>\n",
       "      <td>71535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Washington</td>\n",
       "      <td>1889-11-11</td>\n",
       "      <td>7614893</td>\n",
       "      <td>71362</td>\n",
       "      <td>70979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1863-06-20</td>\n",
       "      <td>1792147</td>\n",
       "      <td>24230</td>\n",
       "      <td>43469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1848-05-29</td>\n",
       "      <td>5822434</td>\n",
       "      <td>65498</td>\n",
       "      <td>59305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1890-07-10</td>\n",
       "      <td>578759</td>\n",
       "      <td>97914</td>\n",
       "      <td>62268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state date_admitted  population  area_sq_mi  \\\n",
       "0          Alabama    1819-12-14     4903185       52419   \n",
       "1           Alaska    1959-01-03      710249      663268   \n",
       "2          Arizona    1912-02-14     7278717      113990   \n",
       "3         Arkansas    1836-06-15     3017804       53179   \n",
       "4       California    1850-09-09    39512223      163696   \n",
       "5         Colorado    1876-08-01     5758736      104094   \n",
       "6      Connecticut    1788-01-09     3565287        5567   \n",
       "7         Delaware    1787-12-07      982895        1982   \n",
       "8          Florida    1845-03-03    21477737       65757   \n",
       "9          Georgia    1788-01-02    10617423       59425   \n",
       "10      HawaiiMoku    1959-08-21     1415872       10931   \n",
       "11           Idaho    1890-07-03     1787065       83569   \n",
       "12        Illinois    1818-12-03    12671821       57915   \n",
       "13         Indiana    1816-12-11     6732219       36418   \n",
       "14            Iowa    1846-12-27     3155070       58295   \n",
       "15          Kansas    1861-01-29     2913314       82278   \n",
       "16        Kentucky    1792-06-01     4467673       40408   \n",
       "17       Louisiana    1812-04-30     4648794       52069   \n",
       "18           Maine    1820-03-15     1344212       35385   \n",
       "19        Maryland    1788-04-28     6045680       12407   \n",
       "20   Massachusetts    1788-02-06     6892503       10565   \n",
       "21        Michigan    1837-01-26     9883635       96716   \n",
       "22       Minnesota    1858-05-11     5639632       86950   \n",
       "23     Mississippi    1817-12-10     2976149       48430   \n",
       "24        Missouri    1821-08-10     6137428       69715   \n",
       "25         Montana    1889-11-08     1068778      147040   \n",
       "26        Nebraska    1867-03-01     1934408       77358   \n",
       "27          Nevada    1864-10-31     3080156      110577   \n",
       "28   New Hampshire    1788-06-21     1359711        9349   \n",
       "29      New Jersey    1787-12-18     8882190        8722   \n",
       "30      New Mexico    1912-01-06     2096829      121590   \n",
       "31        New York    1788-07-26    19453561       54555   \n",
       "32  North Carolina    1789-11-21    10488084       53819   \n",
       "33    North Dakota    1889-11-02      762062       70761   \n",
       "34            Ohio    1803-03-01    11689100       44825   \n",
       "35        Oklahoma    1907-11-16     3956971       69899   \n",
       "36          Oregon    1859-02-14     4217737       98381   \n",
       "37    Pennsylvania    1787-12-12    12801989       46055   \n",
       "38    Rhode Island    1790-05-29     1059361        1214   \n",
       "39  South Carolina    1788-05-23     5148714       32020   \n",
       "40    South Dakota    1889-11-02      884659       77116   \n",
       "41       Tennessee    1796-06-01     6829174       42143   \n",
       "42           Texas    1845-12-29    28995881      268596   \n",
       "43            Utah    1896-01-04     3205958       84899   \n",
       "44         Vermont    1791-03-04      623989        9616   \n",
       "45        Virginia    1788-06-25     8535519       42774   \n",
       "46      Washington    1889-11-11     7614893       71362   \n",
       "47   West Virginia    1863-06-20     1792147       24230   \n",
       "48       Wisconsin    1848-05-29     5822434       65498   \n",
       "49         Wyoming    1890-07-10      578759       97914   \n",
       "\n",
       "    median_household_income  \n",
       "0                     48123  \n",
       "1                     73181  \n",
       "2                     56581  \n",
       "3                     45869  \n",
       "4                     71228  \n",
       "5                     69117  \n",
       "6                     76106  \n",
       "7                     62852  \n",
       "8                     53267  \n",
       "9                     56183  \n",
       "10                    77765  \n",
       "11                    52225  \n",
       "12                    65030  \n",
       "13                    54181  \n",
       "14                    59955  \n",
       "15                    56422  \n",
       "16                    48375  \n",
       "17                    49973  \n",
       "18                    56277  \n",
       "19                    80776  \n",
       "20                    77385  \n",
       "21                    54909  \n",
       "22                    68388  \n",
       "23                    43567  \n",
       "24                    53578  \n",
       "25                    53386  \n",
       "26                    59970  \n",
       "27                    58003  \n",
       "28                    73381  \n",
       "29                    79363  \n",
       "30                    46744  \n",
       "31                    64894  \n",
       "32                    52752  \n",
       "33                    61843  \n",
       "34                    54021  \n",
       "35                    50051  \n",
       "36                    60212  \n",
       "37                    59195  \n",
       "38                    63870  \n",
       "39                    50570  \n",
       "40                    56521  \n",
       "41                    52340  \n",
       "42                    59206  \n",
       "43                    68374  \n",
       "44                    57513  \n",
       "45                    71535  \n",
       "46                    70979  \n",
       "47                    43469  \n",
       "48                    59305  \n",
       "49                    62268  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5\n",
    "state_data.to_csv('state_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
